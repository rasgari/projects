نصب Docker Desktop از وب‌سایت رسمی Docker.

فعال کردن WSL2 (Windows Subsystem for Linux) برای پشتیبانی بهتر از Docker.

دانلود و اجرای Open WebUI
Open WebUI یکی از بهترین گزینه‌ها برای اجرای چت‌بات لوکال است.

مراحل نصب:
اجرای دستور زیر در Docker:

docker run -d -p 3000:8080 --add-host=host.docker.internal:host-gateway -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main


دسترسی به رابط کاربری:

مرورگر را باز کنید و به آدرس http://localhost:3000 بروید.

حساب کاربری ایجاد کنید و مدل مورد نظر خود (مانند Llama 3) را انتخاب کنید.

۴. دانلود و استفاده از مدل‌های LLM
مدل‌هایی مانند Llama 3 یا GPT می‌توانند برای پاسخ به سوالات متداول استفاده شوند.

نصب مدل‌ها:
در محیط Open WebUI یا ابزارهایی مانند Ollama، می‌توانید مدل‌ها را دانلود و اجرا کنید:

ollama run llama3

۵. آپلود فایل‌های FAQ
یکی از قابلیت‌های چت‌بات لوکال این است که می‌توانید فایل‌های متنی (مانند PDF یا TXT) مربوط به سوالات متداول را آپلود کنید تا چت‌بات بتواند بر اساس آنها پاسخ دهد.

مراحل آپلود:
فایل FAQ خود را در رابط کاربری Open WebUI آپلود کنید.

از چت‌بات بخواهید که اطلاعات را خلاصه کند یا سوالات شما را پاسخ دهد.

۶. تنظیمات شبکه لوکال
برای دسترسی کاربران شبکه به چت‌بات:

آدرس IP سیستم میزبان را پیدا کنید.

پورت مربوطه (مانند 3000) را باز کنید تا کاربران بتوانند از طریق مرورگر به چت‌بات دسترسی داشته باشند:

text
http://<Your-IP>:3000
مزایای این روش
حفظ حریم خصوصی داده‌ها، زیرا همه چیز روی شبکه داخلی باقی می‌ماند.

بدون نیاز به اتصال اینترنت.

قابلیت سفارشی‌سازی کامل برای نیازهای خاص کسب‌وکار.

با این روش‌ها، می‌توانید یک چت‌بات هوش مصنوعی قدرتمند برای پاسخگویی به سوالات متداول در شبکه لوکال راه‌اندازی کنید.
